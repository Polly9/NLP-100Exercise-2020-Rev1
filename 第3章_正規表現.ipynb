{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipediaの記事を以下のフォーマットで書き出したファイルjawiki-country.json.gzがある．\n",
    "\n",
    "1行に1記事の情報がJSON形式で格納される\n",
    "各行には記事名が”title”キーに，記事本文が”text”キーの辞書オブジェクトに格納され，そのオブジェクトがJSON形式で書き出される\n",
    "ファイル全体はgzipで圧縮される\n",
    "以下の処理を行うプログラムを作成せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. JSONデータの読み込みPermalink\n",
    "Wikipedia記事のJSONファイルを読み込み，「イギリス」に関する記事本文を表示せよ．問題21-29では，ここで抽出した記事本文に対して実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('../input/jawiki-country.json', lines=True)\n",
    "uk = df.text[df.title=='イギリス'].values\n",
    "print(uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. カテゴリ名を含む行を抽出Permalink\n",
    "記事中でカテゴリ名を宣言している行を抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_json('../input/jawiki-country.json', lines=True)\n",
    "uk = df.text[df.title=='イギリス'].values\n",
    "for line in uk[0].splitlines():\n",
    "    if re.search('Category', line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. カテゴリ名の抽出Permalink\n",
    "記事のカテゴリ名を（行単位ではなく名前で）抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_json('../input/jawiki-country.json', lines=True)\n",
    "uk = df.text[df.title=='イギリス'].values\n",
    "\n",
    "for line in uk[0].splitlines():\n",
    "    if re.search('Category', line):\n",
    "        line = line.replace('[', '').replace(']', '').replace('Category:', '').replace('|元', '').replace('|*', '')\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. セクション構造Permalink\n",
    "記事中に含まれるセクション名とそのレベル（例えば”== セクション名 ==”なら1）を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_json('../input/jawiki-country.json', lines=True)\n",
    "uk = df.text[df.title=='イギリス'].values\n",
    "\n",
    "for line in uk[0].splitlines():\n",
    "    if re.search(\"==+\", line):\n",
    "        section_level = int(line.count('=') / 2 -1)\n",
    "        print(line.replace('=', ''), section_level)\n",
    "\n",
    "#a = 'abcdfgavdfkhfdaoiejrdlsa'\n",
    "#a.count('a')\n",
    "#[OUT] 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. ファイル参照の抽出Permalink\n",
    "記事から参照されているメディアファイルをすべて抜き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_json('../input/jawiki-country.json', lines=True)\n",
    "uk = df.text[df.title=='イギリス'].values\n",
    "for line in uk[0].splitlines():\n",
    "    file = re.findall('File|ファイル:(.+?)\\|', line)\n",
    "    if file:\n",
    "        print(file[0])\n",
    "        \n",
    "#(.+?)  ()で文字を一つのグループにまとめる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. テンプレートの抽出Permalink\n",
    "記事中に含まれる「基礎情報」テンプレートのフィールド名と値を抽出し，辞書オブジェクトとして格納せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_json('../input/jawiki-country.json', lines=True)\n",
    "uk = df.text[df.title=='イギリス'].values\n",
    "\n",
    "basic_info = {}\n",
    "for line in uk[0].splitlines():\n",
    "    file = re.search('\\|(.+?)\\s=\\s*(.+)', line)\n",
    "    if file:\n",
    "        basic_info[file[1]] = file[2]\n",
    "basic_info\n",
    "#\\s 空白表現(\\S 全ての非空白表現)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. 強調マークアップの除去Permalink\n",
    "25の処理時に，テンプレートの値からMediaWikiの強調マークアップ（弱い強調，強調，強い強調のすべて）を除去してテキストに変換せよ（参考: マークアップ早見表）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_json('../input/jawiki-country.json', lines=True)\n",
    "uk = df.text[df.title=='イギリス'].values\n",
    "\n",
    "basic_info = {}\n",
    "for line in uk[0].splitlines():\n",
    "    r = re.search('\\|(.+?)\\s=\\s*(.+)', line)\n",
    "    if r:\n",
    "        basic_info[r[1]] = r[2]\n",
    "    print(re.sub('\\'{2, }(.+?)\\'{2, }', '\\\\1', line))\n",
    "print(basic_info)\n",
    "\n",
    "#{n, } 最小桁数の指定 ex. a{3, } -> aaa, aaaa, aaaaa, ....  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. 内部リンクの除去Permalink\n",
    "26の処理に加えて，テンプレートの値からMediaWikiの内部リンクマークアップを除去し，テキストに変換せよ（参考: マークアップ早見表）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "pattern = re.compile('\\|(.+?)\\s=\\s*(.+)')\n",
    "pattern1 = re.compile('\\'{2,}(.+?)\\'{2,}')\n",
    "pattern2 = re.compile('\\[\\[(.+?)\\]\\]')\n",
    "df = pd.read_json('../input/jawiki-country.json', lines = True)\n",
    "uk = df[df['title']=='イギリス'].text.values\n",
    "lines = uk[0]\n",
    "lines = re.sub(pattern1,'\\\\1', lines)\n",
    "lines = re.sub(pattern2,'\\\\1', lines)\n",
    "ls = lines.split('\\n')\n",
    "d = {}\n",
    "for line in ls:\n",
    "    r = re.search(pattern, line)\n",
    "    if r:\n",
    "        d[r[1]]=r[2]\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. MediaWikiマークアップの除去Permalink\n",
    "27の処理に加えて，テンプレートの値からMediaWikiマークアップを可能な限り除去し，国の基本情報を整形せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "pattern = re.compile('\\|(.+?)\\s=\\s*(.+)')\n",
    "pattern1 = re.compile('\\'{2,}(.+?)\\'{2,}')\n",
    "pattern2 = re.compile('\\[\\[(.+?)\\]\\]')\n",
    "pattern3 = re.compile('<[br|ref][^>]*?>.+?<\\/[br|ref][^>]*?>')\n",
    "df = pd.read_json('../input/jawiki-country.json', lines = True)\n",
    "uk = df[df['title']=='イギリス'].text.values\n",
    "lines = uk[0]\n",
    "lines = re.sub(pattern1,'\\\\1', lines)\n",
    "lines = re.sub(pattern2,'\\\\1', lines)\n",
    "lines = re.sub(pattern3,'', lines)\n",
    "ls = lines.split('\\n')\n",
    "d = {}\n",
    "for line in ls:\n",
    "    r = re.search(pattern, line)\n",
    "    if r:\n",
    "        d[r[1]]=r[2]\n",
    "print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. 国旗画像のURLを取得するPermalink\n",
    "テンプレートの内容を利用し，国旗画像のURLを取得せよ．（ヒント: MediaWiki APIのimageinfoを呼び出して，ファイル参照をURLに変換すればよい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/commons/a/ae/Flag_of_the_United_Kingdom.svg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "pattern = re.compile('\\|(.+?)\\s=\\s*(.+)')\n",
    "df = pd.read_json('../input/jawiki-country.json', lines = True)\n",
    "uk = df[df['title']=='イギリス'].text.values\n",
    "ls = uk[0].split('\\n')\n",
    "d = {}\n",
    "for line in ls:\n",
    "    r = re.search(pattern, line)\n",
    "    if r:\n",
    "        d[r[1]]=r[2]\n",
    "        \n",
    "S = requests.Session()\n",
    "URL = \"https://commons.wikimedia.org/w/api.php\"\n",
    "PARAMS = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"File:\" + d['国旗画像'],\n",
    "    \"prop\": \"imageinfo\",\n",
    "    \"iiprop\":\"url\"\n",
    "}\n",
    "R = S.get(url=URL, params=PARAMS)\n",
    "DATA = R.json()\n",
    "PAGES = DATA['query']['pages']\n",
    "for k, v in PAGES.items():\n",
    "    print (v['imageinfo'][0]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
